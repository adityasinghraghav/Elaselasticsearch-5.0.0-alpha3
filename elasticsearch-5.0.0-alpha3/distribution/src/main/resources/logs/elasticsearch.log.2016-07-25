[2016-07-25 09:59:56,671][INFO ][node                     ] [Damballah] version[5.0.0-alpha3-SNAPSHOT], pid[9852], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 09:59:56,673][INFO ][node                     ] [Damballah] initializing ...
[2016-07-25 09:59:56,694][INFO ][plugins                  ] [Damballah] modules [], plugins []
[2016-07-25 09:59:56,749][INFO ][env                      ] [Damballah] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.9gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 09:59:56,749][INFO ][env                      ] [Damballah] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 10:00:07,102][INFO ][node                     ] [Damballah] initialized
[2016-07-25 10:00:07,102][INFO ][node                     ] [Damballah] starting ...
[2016-07-25 10:00:07,374][INFO ][transport                ] [Damballah] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 10:00:07,403][WARN ][bootstrap                ] [Damballah] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 10:00:11,678][INFO ][cluster.service          ] [Damballah] new_master {Damballah}{cEZaIn4bRyCYbivPSalddQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 10:00:11,772][INFO ][http                     ] [Damballah] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 10:00:11,772][INFO ][node                     ] [Damballah] started
[2016-07-25 10:00:12,510][WARN ][gateway                  ] [Damballah] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:00:12,510][INFO ][gateway                  ] [Damballah] recovered [1] indices into cluster_state
[2016-07-25 10:00:12,832][WARN ][gateway                  ] [Damballah] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:00:13,306][WARN ][gateway                  ] [Damballah] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:00:13,436][INFO ][cluster.routing.allocation] [Damballah] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 10:00:13,438][WARN ][gateway                  ] [Damballah] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:27:58,136][INFO ][node                     ] [Pathway] version[5.0.0-alpha3-SNAPSHOT], pid[9232], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 10:27:58,137][INFO ][node                     ] [Pathway] initializing ...
[2016-07-25 10:27:58,142][INFO ][plugins                  ] [Pathway] modules [], plugins []
[2016-07-25 10:27:58,173][INFO ][env                      ] [Pathway] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.9gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 10:27:58,173][INFO ][env                      ] [Pathway] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 10:28:00,863][INFO ][node                     ] [Pathway] initialized
[2016-07-25 10:28:00,863][INFO ][node                     ] [Pathway] starting ...
[2016-07-25 10:28:01,017][INFO ][transport                ] [Pathway] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 10:28:01,021][WARN ][bootstrap                ] [Pathway] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 10:28:05,071][INFO ][cluster.service          ] [Pathway] new_master {Pathway}{4Qy8Sy3TTqioFj6HR1DIYg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 10:28:05,140][INFO ][http                     ] [Pathway] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 10:28:05,140][INFO ][node                     ] [Pathway] started
[2016-07-25 10:28:05,325][WARN ][gateway                  ] [Pathway] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:28:05,325][INFO ][gateway                  ] [Pathway] recovered [1] indices into cluster_state
[2016-07-25 10:28:05,473][WARN ][gateway                  ] [Pathway] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:28:05,746][WARN ][gateway                  ] [Pathway] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:28:05,782][INFO ][cluster.routing.allocation] [Pathway] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][1]] ...]).
[2016-07-25 10:28:05,785][WARN ][gateway                  ] [Pathway] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:28:41,616][INFO ][node                     ] [Donald Pierce] version[5.0.0-alpha3-SNAPSHOT], pid[5516], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 10:28:41,616][INFO ][node                     ] [Donald Pierce] initializing ...
[2016-07-25 10:28:41,621][INFO ][plugins                  ] [Donald Pierce] modules [], plugins []
[2016-07-25 10:28:41,648][INFO ][env                      ] [Donald Pierce] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.9gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 10:28:41,648][INFO ][env                      ] [Donald Pierce] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 10:28:44,283][INFO ][node                     ] [Donald Pierce] initialized
[2016-07-25 10:28:44,283][INFO ][node                     ] [Donald Pierce] starting ...
[2016-07-25 10:28:44,467][INFO ][transport                ] [Donald Pierce] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 10:28:44,472][WARN ][bootstrap                ] [Donald Pierce] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 10:28:48,566][INFO ][cluster.service          ] [Donald Pierce] new_master {Donald Pierce}{5utQc3TmRkmgvmLCZ8lI6g}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 10:28:48,633][INFO ][http                     ] [Donald Pierce] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 10:28:48,633][INFO ][node                     ] [Donald Pierce] started
[2016-07-25 10:28:48,820][WARN ][gateway                  ] [Donald Pierce] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:28:48,820][INFO ][gateway                  ] [Donald Pierce] recovered [1] indices into cluster_state
[2016-07-25 10:28:48,970][WARN ][gateway                  ] [Donald Pierce] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:28:49,249][WARN ][gateway                  ] [Donald Pierce] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:28:49,281][INFO ][cluster.routing.allocation] [Donald Pierce] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 10:28:49,284][WARN ][gateway                  ] [Donald Pierce] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:48:18,232][INFO ][node                     ] [Warrior Woman] version[5.0.0-alpha3-SNAPSHOT], pid[5272], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 10:48:18,232][INFO ][node                     ] [Warrior Woman] initializing ...
[2016-07-25 10:48:18,239][INFO ][plugins                  ] [Warrior Woman] modules [], plugins []
[2016-07-25 10:48:18,269][INFO ][env                      ] [Warrior Woman] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.9gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 10:48:18,270][INFO ][env                      ] [Warrior Woman] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 10:48:20,793][INFO ][node                     ] [Warrior Woman] initialized
[2016-07-25 10:48:20,793][INFO ][node                     ] [Warrior Woman] starting ...
[2016-07-25 10:48:20,954][INFO ][transport                ] [Warrior Woman] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 10:48:20,962][WARN ][bootstrap                ] [Warrior Woman] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 10:48:25,052][INFO ][cluster.service          ] [Warrior Woman] new_master {Warrior Woman}{t_kQ7drnSkKAntEgJipOSQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 10:48:25,148][INFO ][http                     ] [Warrior Woman] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 10:48:25,148][INFO ][node                     ] [Warrior Woman] started
[2016-07-25 10:48:25,315][WARN ][gateway                  ] [Warrior Woman] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:48:25,315][INFO ][gateway                  ] [Warrior Woman] recovered [1] indices into cluster_state
[2016-07-25 10:48:25,456][WARN ][gateway                  ] [Warrior Woman] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:48:25,687][WARN ][gateway                  ] [Warrior Woman] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:48:25,722][INFO ][cluster.routing.allocation] [Warrior Woman] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][1]] ...]).
[2016-07-25 10:48:25,724][WARN ][gateway                  ] [Warrior Woman] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:50:23,668][INFO ][node                     ] [Locust] version[5.0.0-alpha3-SNAPSHOT], pid[9840], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 10:50:23,668][INFO ][node                     ] [Locust] initializing ...
[2016-07-25 10:50:23,675][INFO ][plugins                  ] [Locust] modules [], plugins []
[2016-07-25 10:50:23,716][INFO ][env                      ] [Locust] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.9gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 10:50:23,716][INFO ][env                      ] [Locust] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 10:50:26,393][INFO ][node                     ] [Locust] initialized
[2016-07-25 10:50:26,393][INFO ][node                     ] [Locust] starting ...
[2016-07-25 10:50:26,559][INFO ][transport                ] [Locust] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 10:50:26,564][WARN ][bootstrap                ] [Locust] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 10:50:30,609][INFO ][cluster.service          ] [Locust] new_master {Locust}{2vKYI1eqRNWbKZ5x3ktE_Q}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 10:50:30,673][INFO ][http                     ] [Locust] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 10:50:30,673][INFO ][node                     ] [Locust] started
[2016-07-25 10:50:30,865][WARN ][gateway                  ] [Locust] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:50:30,865][INFO ][gateway                  ] [Locust] recovered [1] indices into cluster_state
[2016-07-25 10:50:31,020][WARN ][gateway                  ] [Locust] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:50:31,301][WARN ][gateway                  ] [Locust] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 10:50:31,333][INFO ][cluster.routing.allocation] [Locust] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][2]] ...]).
[2016-07-25 10:50:31,335][WARN ][gateway                  ] [Locust] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 11:15:53,364][DEBUG][action.search            ] [Locust] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:637)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 11:15:53,368][WARN ][rest.suppressed          ] path: /products/_search, params: {scroll=1m, index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:637)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 11:17:26,822][DEBUG][action.search            ] [Locust] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:637)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 11:17:26,822][WARN ][rest.suppressed          ] path: /products/_search, params: {scroll=1m, index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:637)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 11:20:00,725][INFO ][node                     ] [Moondragon] version[5.0.0-alpha3-SNAPSHOT], pid[4960], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 11:20:00,725][INFO ][node                     ] [Moondragon] initializing ...
[2016-07-25 11:20:00,732][INFO ][plugins                  ] [Moondragon] modules [], plugins []
[2016-07-25 11:20:00,761][INFO ][env                      ] [Moondragon] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.9gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 11:20:00,761][INFO ][env                      ] [Moondragon] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 11:20:03,299][INFO ][node                     ] [Moondragon] initialized
[2016-07-25 11:20:03,299][INFO ][node                     ] [Moondragon] starting ...
[2016-07-25 11:20:03,450][INFO ][transport                ] [Moondragon] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 11:20:03,458][WARN ][bootstrap                ] [Moondragon] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 11:20:07,552][INFO ][cluster.service          ] [Moondragon] new_master {Moondragon}{yPCkhL4RQ2GfySgHtR_JvA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 11:20:07,642][INFO ][http                     ] [Moondragon] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 11:20:07,642][INFO ][node                     ] [Moondragon] started
[2016-07-25 11:20:07,844][WARN ][gateway                  ] [Moondragon] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 11:20:07,844][INFO ][gateway                  ] [Moondragon] recovered [1] indices into cluster_state
[2016-07-25 11:20:08,017][WARN ][gateway                  ] [Moondragon] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 11:20:08,295][WARN ][gateway                  ] [Moondragon] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 11:20:08,327][INFO ][cluster.routing.allocation] [Moondragon] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 11:20:08,330][WARN ][gateway                  ] [Moondragon] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 11:21:05,744][DEBUG][action.search            ] [Moondragon] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:637)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 11:21:05,750][WARN ][rest.suppressed          ] path: /products/_search, params: {scroll=1m, index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:637)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 12:19:11,526][INFO ][node                     ] [Harrier] version[5.0.0-alpha3-SNAPSHOT], pid[3196], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 12:19:11,526][INFO ][node                     ] [Harrier] initializing ...
[2016-07-25 12:19:11,533][INFO ][plugins                  ] [Harrier] modules [], plugins []
[2016-07-25 12:19:11,568][INFO ][env                      ] [Harrier] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 12:19:11,568][INFO ][env                      ] [Harrier] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 12:19:14,177][INFO ][node                     ] [Harrier] initialized
[2016-07-25 12:19:14,178][INFO ][node                     ] [Harrier] starting ...
[2016-07-25 12:19:14,344][INFO ][transport                ] [Harrier] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 12:19:14,349][WARN ][bootstrap                ] [Harrier] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 12:19:18,435][INFO ][cluster.service          ] [Harrier] new_master {Harrier}{Acz96KhTSuW59AMKLcsxvw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 12:19:18,532][INFO ][http                     ] [Harrier] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 12:19:18,532][INFO ][node                     ] [Harrier] started
[2016-07-25 12:19:18,715][WARN ][gateway                  ] [Harrier] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 12:19:18,715][INFO ][gateway                  ] [Harrier] recovered [1] indices into cluster_state
[2016-07-25 12:19:18,899][WARN ][gateway                  ] [Harrier] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 12:19:19,144][WARN ][gateway                  ] [Harrier] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 12:19:19,207][INFO ][cluster.routing.allocation] [Harrier] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 12:19:19,210][WARN ][gateway                  ] [Harrier] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:49:18,163][INFO ][node                     ] [Vavavoom] version[5.0.0-alpha3-SNAPSHOT], pid[3900], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 14:49:18,163][INFO ][node                     ] [Vavavoom] initializing ...
[2016-07-25 14:49:18,171][INFO ][plugins                  ] [Vavavoom] modules [], plugins []
[2016-07-25 14:49:18,203][INFO ][env                      ] [Vavavoom] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 14:49:18,203][INFO ][env                      ] [Vavavoom] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 14:49:20,887][INFO ][node                     ] [Vavavoom] initialized
[2016-07-25 14:49:20,887][INFO ][node                     ] [Vavavoom] starting ...
[2016-07-25 14:49:21,052][INFO ][transport                ] [Vavavoom] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 14:49:21,057][WARN ][bootstrap                ] [Vavavoom] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 14:49:25,154][INFO ][cluster.service          ] [Vavavoom] new_master {Vavavoom}{fNuho8b3Q1SMFbTZmhEOFQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 14:49:25,254][INFO ][http                     ] [Vavavoom] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 14:49:25,255][INFO ][node                     ] [Vavavoom] started
[2016-07-25 14:49:25,410][WARN ][gateway                  ] [Vavavoom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:49:25,410][INFO ][gateway                  ] [Vavavoom] recovered [1] indices into cluster_state
[2016-07-25 14:49:25,545][WARN ][gateway                  ] [Vavavoom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:49:25,766][WARN ][gateway                  ] [Vavavoom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:49:25,798][INFO ][cluster.routing.allocation] [Vavavoom] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 14:49:25,801][WARN ][gateway                  ] [Vavavoom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:53:32,997][INFO ][node                     ] [Gladiatrix] version[5.0.0-alpha3-SNAPSHOT], pid[1792], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 14:53:32,997][INFO ][node                     ] [Gladiatrix] initializing ...
[2016-07-25 14:53:33,004][INFO ][plugins                  ] [Gladiatrix] modules [], plugins []
[2016-07-25 14:53:33,042][INFO ][env                      ] [Gladiatrix] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 14:53:33,042][INFO ][env                      ] [Gladiatrix] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 14:53:35,599][INFO ][node                     ] [Gladiatrix] initialized
[2016-07-25 14:53:35,599][INFO ][node                     ] [Gladiatrix] starting ...
[2016-07-25 14:53:35,779][INFO ][transport                ] [Gladiatrix] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 14:53:35,786][WARN ][bootstrap                ] [Gladiatrix] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 14:53:39,888][INFO ][cluster.service          ] [Gladiatrix] new_master {Gladiatrix}{rdUTYmPORreNstjGpYJtlw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 14:53:39,981][INFO ][http                     ] [Gladiatrix] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 14:53:39,981][INFO ][node                     ] [Gladiatrix] started
[2016-07-25 14:53:40,165][WARN ][gateway                  ] [Gladiatrix] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:53:40,165][INFO ][gateway                  ] [Gladiatrix] recovered [1] indices into cluster_state
[2016-07-25 14:53:40,320][WARN ][gateway                  ] [Gladiatrix] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:53:40,606][WARN ][gateway                  ] [Gladiatrix] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:53:40,673][INFO ][cluster.routing.allocation] [Gladiatrix] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 14:53:40,677][WARN ][gateway                  ] [Gladiatrix] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:03,036][INFO ][node                     ] [Man-Beast] version[5.0.0-alpha3-SNAPSHOT], pid[120], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 14:55:03,037][INFO ][node                     ] [Man-Beast] initializing ...
[2016-07-25 14:55:03,044][INFO ][plugins                  ] [Man-Beast] modules [], plugins []
[2016-07-25 14:55:03,075][INFO ][env                      ] [Man-Beast] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 14:55:03,076][INFO ][env                      ] [Man-Beast] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 14:55:05,708][INFO ][node                     ] [Man-Beast] initialized
[2016-07-25 14:55:05,708][INFO ][node                     ] [Man-Beast] starting ...
[2016-07-25 14:55:05,886][INFO ][transport                ] [Man-Beast] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 14:55:05,891][WARN ][bootstrap                ] [Man-Beast] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 14:55:09,991][INFO ][cluster.service          ] [Man-Beast] new_master {Man-Beast}{VshmqFBAQhaIvp4tIr4exw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 14:55:10,095][INFO ][http                     ] [Man-Beast] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 14:55:10,095][INFO ][node                     ] [Man-Beast] started
[2016-07-25 14:55:10,247][WARN ][gateway                  ] [Man-Beast] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:10,247][INFO ][gateway                  ] [Man-Beast] recovered [1] indices into cluster_state
[2016-07-25 14:55:10,388][WARN ][gateway                  ] [Man-Beast] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:10,612][WARN ][gateway                  ] [Man-Beast] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:10,647][INFO ][cluster.routing.allocation] [Man-Beast] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 14:55:10,649][WARN ][gateway                  ] [Man-Beast] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:40,239][INFO ][node                     ] [Supercharger] version[5.0.0-alpha3-SNAPSHOT], pid[7568], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 14:55:40,239][INFO ][node                     ] [Supercharger] initializing ...
[2016-07-25 14:55:40,248][INFO ][plugins                  ] [Supercharger] modules [], plugins []
[2016-07-25 14:55:40,279][INFO ][env                      ] [Supercharger] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 14:55:40,279][INFO ][env                      ] [Supercharger] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 14:55:42,787][INFO ][node                     ] [Supercharger] initialized
[2016-07-25 14:55:42,787][INFO ][node                     ] [Supercharger] starting ...
[2016-07-25 14:55:42,952][INFO ][transport                ] [Supercharger] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 14:55:42,956][WARN ][bootstrap                ] [Supercharger] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 14:55:47,052][INFO ][cluster.service          ] [Supercharger] new_master {Supercharger}{jnIqHPwFRtKNnMggQrbFpA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 14:55:47,135][INFO ][http                     ] [Supercharger] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 14:55:47,135][INFO ][node                     ] [Supercharger] started
[2016-07-25 14:55:47,305][WARN ][gateway                  ] [Supercharger] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:47,305][INFO ][gateway                  ] [Supercharger] recovered [1] indices into cluster_state
[2016-07-25 14:55:47,436][WARN ][gateway                  ] [Supercharger] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:47,671][WARN ][gateway                  ] [Supercharger] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:55:47,699][INFO ][cluster.routing.allocation] [Supercharger] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 14:55:47,702][WARN ][gateway                  ] [Supercharger] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:56:54,350][INFO ][node                     ] [Quantum] version[5.0.0-alpha3-SNAPSHOT], pid[3024], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 14:56:54,350][INFO ][node                     ] [Quantum] initializing ...
[2016-07-25 14:56:54,356][INFO ][plugins                  ] [Quantum] modules [], plugins []
[2016-07-25 14:56:54,387][INFO ][env                      ] [Quantum] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 14:56:54,387][INFO ][env                      ] [Quantum] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 14:56:56,937][INFO ][node                     ] [Quantum] initialized
[2016-07-25 14:56:56,937][INFO ][node                     ] [Quantum] starting ...
[2016-07-25 14:56:57,096][INFO ][transport                ] [Quantum] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 14:56:57,106][WARN ][bootstrap                ] [Quantum] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 14:57:01,193][INFO ][cluster.service          ] [Quantum] new_master {Quantum}{B-4iDbYcRvqFvP9Smnjr1g}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 14:57:01,277][INFO ][http                     ] [Quantum] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 14:57:01,277][INFO ][node                     ] [Quantum] started
[2016-07-25 14:57:01,466][WARN ][gateway                  ] [Quantum] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:57:01,466][INFO ][gateway                  ] [Quantum] recovered [1] indices into cluster_state
[2016-07-25 14:57:01,625][WARN ][gateway                  ] [Quantum] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:57:01,894][WARN ][gateway                  ] [Quantum] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:57:01,944][INFO ][cluster.routing.allocation] [Quantum] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 14:57:01,947][WARN ][gateway                  ] [Quantum] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:59:06,683][INFO ][node                     ] [Benedict Kine] version[5.0.0-alpha3-SNAPSHOT], pid[5492], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 14:59:06,684][INFO ][node                     ] [Benedict Kine] initializing ...
[2016-07-25 14:59:06,689][INFO ][plugins                  ] [Benedict Kine] modules [], plugins []
[2016-07-25 14:59:06,720][INFO ][env                      ] [Benedict Kine] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 14:59:06,721][INFO ][env                      ] [Benedict Kine] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 14:59:09,246][INFO ][node                     ] [Benedict Kine] initialized
[2016-07-25 14:59:09,246][INFO ][node                     ] [Benedict Kine] starting ...
[2016-07-25 14:59:09,413][INFO ][transport                ] [Benedict Kine] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 14:59:09,417][WARN ][bootstrap                ] [Benedict Kine] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 14:59:13,490][INFO ][cluster.service          ] [Benedict Kine] new_master {Benedict Kine}{JZV_WePXT1WmhSv2WUxoWg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 14:59:13,573][INFO ][http                     ] [Benedict Kine] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 14:59:13,574][INFO ][node                     ] [Benedict Kine] started
[2016-07-25 14:59:13,766][WARN ][gateway                  ] [Benedict Kine] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:59:13,766][INFO ][gateway                  ] [Benedict Kine] recovered [1] indices into cluster_state
[2016-07-25 14:59:13,922][WARN ][gateway                  ] [Benedict Kine] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:59:14,207][WARN ][gateway                  ] [Benedict Kine] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 14:59:14,267][INFO ][cluster.routing.allocation] [Benedict Kine] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 14:59:14,270][WARN ][gateway                  ] [Benedict Kine] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:06:59,111][INFO ][node                     ] [X-Cutioner] version[5.0.0-alpha3-SNAPSHOT], pid[6848], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:06:59,112][INFO ][node                     ] [X-Cutioner] initializing ...
[2016-07-25 15:06:59,117][INFO ][plugins                  ] [X-Cutioner] modules [], plugins []
[2016-07-25 15:06:59,146][INFO ][env                      ] [X-Cutioner] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:06:59,146][INFO ][env                      ] [X-Cutioner] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:07:01,652][INFO ][node                     ] [X-Cutioner] initialized
[2016-07-25 15:07:01,652][INFO ][node                     ] [X-Cutioner] starting ...
[2016-07-25 15:07:01,812][INFO ][transport                ] [X-Cutioner] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:07:01,820][WARN ][bootstrap                ] [X-Cutioner] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:07:05,896][INFO ][cluster.service          ] [X-Cutioner] new_master {X-Cutioner}{kbupJs3mQaW--z7F_mdDhw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:07:05,973][INFO ][http                     ] [X-Cutioner] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:07:05,973][INFO ][node                     ] [X-Cutioner] started
[2016-07-25 15:07:06,174][WARN ][gateway                  ] [X-Cutioner] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:07:06,174][INFO ][gateway                  ] [X-Cutioner] recovered [1] indices into cluster_state
[2016-07-25 15:07:06,349][WARN ][gateway                  ] [X-Cutioner] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:07:06,630][WARN ][gateway                  ] [X-Cutioner] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:07:06,635][WARN ][gateway                  ] [X-Cutioner] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:07:06,696][INFO ][cluster.routing.allocation] [X-Cutioner] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 15:07:06,700][WARN ][gateway                  ] [X-Cutioner] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:07:10,088][DEBUG][action.search            ] [X-Cutioner] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 91
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:595)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:07:10,098][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 91
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:595)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:08:21,299][INFO ][node                     ] [Calvin Rankin] version[5.0.0-alpha3-SNAPSHOT], pid[8868], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:08:21,299][INFO ][node                     ] [Calvin Rankin] initializing ...
[2016-07-25 15:08:21,305][INFO ][plugins                  ] [Calvin Rankin] modules [], plugins []
[2016-07-25 15:08:21,337][INFO ][env                      ] [Calvin Rankin] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:08:21,337][INFO ][env                      ] [Calvin Rankin] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:08:23,877][INFO ][node                     ] [Calvin Rankin] initialized
[2016-07-25 15:08:23,877][INFO ][node                     ] [Calvin Rankin] starting ...
[2016-07-25 15:08:24,050][INFO ][transport                ] [Calvin Rankin] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:08:24,055][WARN ][bootstrap                ] [Calvin Rankin] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:08:28,098][INFO ][cluster.service          ] [Calvin Rankin] new_master {Calvin Rankin}{rxAZWZDbQf6Z90h3YTEGvw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:08:28,168][INFO ][http                     ] [Calvin Rankin] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:08:28,168][INFO ][node                     ] [Calvin Rankin] started
[2016-07-25 15:08:28,346][WARN ][gateway                  ] [Calvin Rankin] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:08:28,346][INFO ][gateway                  ] [Calvin Rankin] recovered [1] indices into cluster_state
[2016-07-25 15:08:28,486][WARN ][gateway                  ] [Calvin Rankin] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:08:28,721][WARN ][gateway                  ] [Calvin Rankin] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:08:28,755][INFO ][cluster.routing.allocation] [Calvin Rankin] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][1]] ...]).
[2016-07-25 15:08:28,757][WARN ][gateway                  ] [Calvin Rankin] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:09:08,744][INFO ][node                     ] [Red Guardian] version[5.0.0-alpha3-SNAPSHOT], pid[10176], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:09:08,744][INFO ][node                     ] [Red Guardian] initializing ...
[2016-07-25 15:09:08,750][INFO ][plugins                  ] [Red Guardian] modules [], plugins []
[2016-07-25 15:09:08,782][INFO ][env                      ] [Red Guardian] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:09:08,782][INFO ][env                      ] [Red Guardian] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:09:11,282][INFO ][node                     ] [Red Guardian] initialized
[2016-07-25 15:09:11,282][INFO ][node                     ] [Red Guardian] starting ...
[2016-07-25 15:09:11,456][INFO ][transport                ] [Red Guardian] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:09:11,460][WARN ][bootstrap                ] [Red Guardian] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:09:15,559][INFO ][cluster.service          ] [Red Guardian] new_master {Red Guardian}{9iq653YrS_6nMREoIFrnzw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:09:15,642][INFO ][http                     ] [Red Guardian] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:09:15,642][INFO ][node                     ] [Red Guardian] started
[2016-07-25 15:09:15,827][WARN ][gateway                  ] [Red Guardian] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:09:15,827][INFO ][gateway                  ] [Red Guardian] recovered [1] indices into cluster_state
[2016-07-25 15:09:15,989][WARN ][gateway                  ] [Red Guardian] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:09:16,259][WARN ][gateway                  ] [Red Guardian] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:09:16,292][INFO ][cluster.routing.allocation] [Red Guardian] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:09:16,295][WARN ][gateway                  ] [Red Guardian] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:10:06,665][INFO ][node                     ] [Dragon Man] version[5.0.0-alpha3-SNAPSHOT], pid[7224], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:10:06,666][INFO ][node                     ] [Dragon Man] initializing ...
[2016-07-25 15:10:06,674][INFO ][plugins                  ] [Dragon Man] modules [], plugins []
[2016-07-25 15:10:06,711][INFO ][env                      ] [Dragon Man] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:10:06,711][INFO ][env                      ] [Dragon Man] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:10:09,298][INFO ][node                     ] [Dragon Man] initialized
[2016-07-25 15:10:09,298][INFO ][node                     ] [Dragon Man] starting ...
[2016-07-25 15:10:09,458][INFO ][transport                ] [Dragon Man] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:10:09,463][WARN ][bootstrap                ] [Dragon Man] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:10:13,564][INFO ][cluster.service          ] [Dragon Man] new_master {Dragon Man}{QaCll8PITt6xJmfa9U_SDw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:10:13,652][INFO ][http                     ] [Dragon Man] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:10:13,652][INFO ][node                     ] [Dragon Man] started
[2016-07-25 15:10:13,811][WARN ][gateway                  ] [Dragon Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:10:13,812][INFO ][gateway                  ] [Dragon Man] recovered [1] indices into cluster_state
[2016-07-25 15:10:13,944][WARN ][gateway                  ] [Dragon Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:10:14,170][WARN ][gateway                  ] [Dragon Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:10:14,204][INFO ][cluster.routing.allocation] [Dragon Man] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:10:14,207][WARN ][gateway                  ] [Dragon Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:10:56,603][INFO ][node                     ] [Patsy Walker] version[5.0.0-alpha3-SNAPSHOT], pid[6784], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:10:56,604][INFO ][node                     ] [Patsy Walker] initializing ...
[2016-07-25 15:10:56,609][INFO ][plugins                  ] [Patsy Walker] modules [], plugins []
[2016-07-25 15:10:56,638][INFO ][env                      ] [Patsy Walker] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:10:56,639][INFO ][env                      ] [Patsy Walker] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:10:59,071][INFO ][node                     ] [Patsy Walker] initialized
[2016-07-25 15:10:59,071][INFO ][node                     ] [Patsy Walker] starting ...
[2016-07-25 15:10:59,235][INFO ][transport                ] [Patsy Walker] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:10:59,243][WARN ][bootstrap                ] [Patsy Walker] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:11:03,292][INFO ][cluster.service          ] [Patsy Walker] new_master {Patsy Walker}{5a9ueO6ZT_SWwv-uhIBbzw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:11:03,360][INFO ][http                     ] [Patsy Walker] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:11:03,360][INFO ][node                     ] [Patsy Walker] started
[2016-07-25 15:11:03,541][WARN ][gateway                  ] [Patsy Walker] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:11:03,541][INFO ][gateway                  ] [Patsy Walker] recovered [1] indices into cluster_state
[2016-07-25 15:11:03,681][WARN ][gateway                  ] [Patsy Walker] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:11:03,974][WARN ][gateway                  ] [Patsy Walker] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:11:04,011][INFO ][cluster.routing.allocation] [Patsy Walker] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][1]] ...]).
[2016-07-25 15:11:04,014][WARN ][gateway                  ] [Patsy Walker] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:11:52,830][INFO ][node                     ] [Elias Bogan] version[5.0.0-alpha3-SNAPSHOT], pid[7812], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:11:52,831][INFO ][node                     ] [Elias Bogan] initializing ...
[2016-07-25 15:11:52,839][INFO ][plugins                  ] [Elias Bogan] modules [], plugins []
[2016-07-25 15:11:52,887][INFO ][env                      ] [Elias Bogan] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:11:52,887][INFO ][env                      ] [Elias Bogan] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:11:55,322][INFO ][node                     ] [Elias Bogan] initialized
[2016-07-25 15:11:55,322][INFO ][node                     ] [Elias Bogan] starting ...
[2016-07-25 15:11:55,495][INFO ][transport                ] [Elias Bogan] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:11:55,503][WARN ][bootstrap                ] [Elias Bogan] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:11:59,558][INFO ][cluster.service          ] [Elias Bogan] new_master {Elias Bogan}{-dQBgCW0SgmY8C7PGdLYTg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:11:59,632][INFO ][http                     ] [Elias Bogan] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:11:59,632][INFO ][node                     ] [Elias Bogan] started
[2016-07-25 15:11:59,672][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
ClusterBlockException[blocked by: [SERVICE_UNAVAILABLE/1/state not recovered / initialized];]
	at org.elasticsearch.cluster.block.ClusterBlocks.globalBlockedException(ClusterBlocks.java:157)
	at org.elasticsearch.cluster.block.ClusterBlocks.globalBlockedRaiseException(ClusterBlocks.java:147)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.<init>(AbstractSearchAsyncAction.java:94)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction.<init>(SearchQueryThenFetchAsyncAction.java:53)
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:106)
	at org.elasticsearch.action.search.TransportSearchAction.doExecute(TransportSearchAction.java:48)
	at org.elasticsearch.action.support.TransportAction.doExecute(TransportAction.java:150)
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:174)
	at org.elasticsearch.action.ingest.IngestActionFilter.apply(IngestActionFilter.java:80)
	at org.elasticsearch.action.support.TransportAction$RequestFilterChain.proceed(TransportAction.java:172)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:145)
	at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:87)
	at org.elasticsearch.client.node.NodeClient.doExecute(NodeClient.java:64)
	at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:394)
	at org.elasticsearch.client.support.AbstractClient.search(AbstractClient.java:521)
	at org.elasticsearch.rest.action.search.RestSearchAction.handleRequest(RestSearchAction.java:96)
	at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:51)
	at org.elasticsearch.rest.RestController.executeHandler(RestController.java:215)
	at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:174)
	at org.elasticsearch.http.HttpServer.dispatchRequest(HttpServer.java:114)
	at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:490)
	at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:65)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:85)
	at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpContentEncoder.messageReceived(HttpContentEncoder.java:82)
	at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:108)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)
	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)
	at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)
	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)
	at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:83)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)
	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)
	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)
	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:11:59,860][WARN ][gateway                  ] [Elias Bogan] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:11:59,860][INFO ][gateway                  ] [Elias Bogan] recovered [1] indices into cluster_state
[2016-07-25 15:12:00,025][WARN ][gateway                  ] [Elias Bogan] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:12:00,294][WARN ][gateway                  ] [Elias Bogan] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:12:00,337][INFO ][cluster.routing.allocation] [Elias Bogan] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:12:00,339][WARN ][gateway                  ] [Elias Bogan] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:12:24,132][DEBUG][action.search            ] [Elias Bogan] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 91
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:595)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:12:24,133][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 91
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:595)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:12:25,952][INFO ][node                     ] [Skullcrusher] version[5.0.0-alpha3-SNAPSHOT], pid[100], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:12:25,952][INFO ][node                     ] [Skullcrusher] initializing ...
[2016-07-25 15:12:25,958][INFO ][plugins                  ] [Skullcrusher] modules [], plugins []
[2016-07-25 15:12:25,991][INFO ][env                      ] [Skullcrusher] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:12:25,991][INFO ][env                      ] [Skullcrusher] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:12:28,483][INFO ][node                     ] [Skullcrusher] initialized
[2016-07-25 15:12:28,484][INFO ][node                     ] [Skullcrusher] starting ...
[2016-07-25 15:12:28,650][INFO ][transport                ] [Skullcrusher] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:12:28,657][WARN ][bootstrap                ] [Skullcrusher] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:12:32,736][INFO ][cluster.service          ] [Skullcrusher] new_master {Skullcrusher}{vm0FWdHtT_Gci-eA87N2gA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:12:32,823][INFO ][http                     ] [Skullcrusher] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:12:32,823][INFO ][node                     ] [Skullcrusher] started
[2016-07-25 15:12:33,010][WARN ][gateway                  ] [Skullcrusher] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:12:33,010][INFO ][gateway                  ] [Skullcrusher] recovered [1] indices into cluster_state
[2016-07-25 15:12:33,159][WARN ][gateway                  ] [Skullcrusher] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:12:33,464][WARN ][gateway                  ] [Skullcrusher] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:12:33,494][INFO ][cluster.routing.allocation] [Skullcrusher] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 15:12:33,497][WARN ][gateway                  ] [Skullcrusher] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:14:11,970][INFO ][node                     ] [Micro] version[5.0.0-alpha3-SNAPSHOT], pid[6680], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:14:11,971][INFO ][node                     ] [Micro] initializing ...
[2016-07-25 15:14:11,976][INFO ][plugins                  ] [Micro] modules [], plugins []
[2016-07-25 15:14:12,007][INFO ][env                      ] [Micro] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:14:12,007][INFO ][env                      ] [Micro] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:14:14,556][INFO ][node                     ] [Micro] initialized
[2016-07-25 15:14:14,556][INFO ][node                     ] [Micro] starting ...
[2016-07-25 15:14:14,744][INFO ][transport                ] [Micro] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:14:14,749][WARN ][bootstrap                ] [Micro] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:14:18,879][INFO ][cluster.service          ] [Micro] new_master {Micro}{MrW9cBIuTzGa6UyRKri1ng}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:14:18,963][INFO ][http                     ] [Micro] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:14:18,963][INFO ][node                     ] [Micro] started
[2016-07-25 15:14:19,150][WARN ][gateway                  ] [Micro] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:14:19,150][INFO ][gateway                  ] [Micro] recovered [1] indices into cluster_state
[2016-07-25 15:14:19,326][WARN ][gateway                  ] [Micro] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:14:19,592][WARN ][gateway                  ] [Micro] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:14:19,634][INFO ][cluster.routing.allocation] [Micro] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][2]] ...]).
[2016-07-25 15:14:19,638][WARN ][gateway                  ] [Micro] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:15:48,328][DEBUG][action.search            ] [Micro] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:15:48,331][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:15:59,848][INFO ][node                     ] [Matador] version[5.0.0-alpha3-SNAPSHOT], pid[4488], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:15:59,849][INFO ][node                     ] [Matador] initializing ...
[2016-07-25 15:15:59,854][INFO ][plugins                  ] [Matador] modules [], plugins []
[2016-07-25 15:15:59,884][INFO ][env                      ] [Matador] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:15:59,884][INFO ][env                      ] [Matador] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:16:02,406][INFO ][node                     ] [Matador] initialized
[2016-07-25 15:16:02,406][INFO ][node                     ] [Matador] starting ...
[2016-07-25 15:16:02,572][INFO ][transport                ] [Matador] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:16:02,580][WARN ][bootstrap                ] [Matador] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:16:06,627][INFO ][cluster.service          ] [Matador] new_master {Matador}{eWA1VZc4RxizeD6d54oGMg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:16:06,701][INFO ][http                     ] [Matador] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:16:06,701][INFO ][node                     ] [Matador] started
[2016-07-25 15:16:06,885][WARN ][gateway                  ] [Matador] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:16:06,885][INFO ][gateway                  ] [Matador] recovered [1] indices into cluster_state
[2016-07-25 15:16:07,045][WARN ][gateway                  ] [Matador] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:16:07,365][WARN ][gateway                  ] [Matador] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:16:07,402][INFO ][cluster.routing.allocation] [Matador] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 15:16:07,404][WARN ][gateway                  ] [Matador] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:17:12,686][DEBUG][action.search            ] [Matador] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:17:12,691][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:18:28,614][DEBUG][action.search            ] [Matador] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:18:28,615][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:18:28,771][DEBUG][action.search            ] [Matador] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:18:28,772][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:19:41,623][DEBUG][action.search            ] [Matador] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:19:41,624][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.ArrayIndexOutOfBoundsException: 20
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:597)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
[2016-07-25 15:20:21,938][INFO ][node                     ] [Doctor Doom] version[5.0.0-alpha3-SNAPSHOT], pid[10192], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:20:21,938][INFO ][node                     ] [Doctor Doom] initializing ...
[2016-07-25 15:20:21,943][INFO ][plugins                  ] [Doctor Doom] modules [], plugins []
[2016-07-25 15:20:21,974][INFO ][env                      ] [Doctor Doom] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:20:21,974][INFO ][env                      ] [Doctor Doom] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:20:24,500][INFO ][node                     ] [Doctor Doom] initialized
[2016-07-25 15:20:24,501][INFO ][node                     ] [Doctor Doom] starting ...
[2016-07-25 15:20:24,670][INFO ][transport                ] [Doctor Doom] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:20:24,674][WARN ][bootstrap                ] [Doctor Doom] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:20:28,775][INFO ][cluster.service          ] [Doctor Doom] new_master {Doctor Doom}{HgEXwd0HSQK9P9gur1EZHw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:20:28,875][INFO ][http                     ] [Doctor Doom] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:20:28,876][INFO ][node                     ] [Doctor Doom] started
[2016-07-25 15:20:29,071][WARN ][gateway                  ] [Doctor Doom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:20:29,071][INFO ][gateway                  ] [Doctor Doom] recovered [1] indices into cluster_state
[2016-07-25 15:20:29,250][WARN ][gateway                  ] [Doctor Doom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:20:29,552][WARN ][gateway                  ] [Doctor Doom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:20:29,593][INFO ][cluster.routing.allocation] [Doctor Doom] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:20:29,596][WARN ][gateway                  ] [Doctor Doom] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:22:56,389][INFO ][node                     ] [Slipstream] version[5.0.0-alpha3-SNAPSHOT], pid[1960], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:22:56,389][INFO ][node                     ] [Slipstream] initializing ...
[2016-07-25 15:22:56,395][INFO ][plugins                  ] [Slipstream] modules [], plugins []
[2016-07-25 15:22:56,432][INFO ][env                      ] [Slipstream] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:22:56,432][INFO ][env                      ] [Slipstream] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:22:59,007][INFO ][node                     ] [Slipstream] initialized
[2016-07-25 15:22:59,007][INFO ][node                     ] [Slipstream] starting ...
[2016-07-25 15:22:59,159][INFO ][transport                ] [Slipstream] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:22:59,167][WARN ][bootstrap                ] [Slipstream] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:23:03,226][INFO ][cluster.service          ] [Slipstream] new_master {Slipstream}{xr38Z4bwQW6b99mZmofy_A}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:23:03,301][INFO ][http                     ] [Slipstream] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:23:03,301][INFO ][node                     ] [Slipstream] started
[2016-07-25 15:23:03,470][WARN ][gateway                  ] [Slipstream] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:23:03,470][INFO ][gateway                  ] [Slipstream] recovered [1] indices into cluster_state
[2016-07-25 15:23:03,605][WARN ][gateway                  ] [Slipstream] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:23:03,864][WARN ][gateway                  ] [Slipstream] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:23:03,932][INFO ][cluster.routing.allocation] [Slipstream] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 15:23:03,934][WARN ][gateway                  ] [Slipstream] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:24:58,650][INFO ][node                     ] [Sugar Man] version[5.0.0-alpha3-SNAPSHOT], pid[8604], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:24:58,650][INFO ][node                     ] [Sugar Man] initializing ...
[2016-07-25 15:24:58,658][INFO ][plugins                  ] [Sugar Man] modules [], plugins []
[2016-07-25 15:24:58,701][INFO ][env                      ] [Sugar Man] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:24:58,701][INFO ][env                      ] [Sugar Man] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:25:01,319][INFO ][node                     ] [Sugar Man] initialized
[2016-07-25 15:25:01,319][INFO ][node                     ] [Sugar Man] starting ...
[2016-07-25 15:25:01,500][INFO ][transport                ] [Sugar Man] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:25:01,504][WARN ][bootstrap                ] [Sugar Man] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:25:05,601][INFO ][cluster.service          ] [Sugar Man] new_master {Sugar Man}{HMKO1-ZCRqGyKNRcMXgGqw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:25:05,680][INFO ][http                     ] [Sugar Man] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:25:05,680][INFO ][node                     ] [Sugar Man] started
[2016-07-25 15:25:05,844][WARN ][gateway                  ] [Sugar Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:25:05,844][INFO ][gateway                  ] [Sugar Man] recovered [1] indices into cluster_state
[2016-07-25 15:25:05,986][WARN ][gateway                  ] [Sugar Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:25:06,236][WARN ][gateway                  ] [Sugar Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:25:06,273][INFO ][cluster.routing.allocation] [Sugar Man] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 15:25:06,276][WARN ][gateway                  ] [Sugar Man] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:25:57,802][INFO ][node                     ] [Wallflower] version[5.0.0-alpha3-SNAPSHOT], pid[8152], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:25:57,802][INFO ][node                     ] [Wallflower] initializing ...
[2016-07-25 15:25:57,809][INFO ][plugins                  ] [Wallflower] modules [], plugins []
[2016-07-25 15:25:57,842][INFO ][env                      ] [Wallflower] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:25:57,842][INFO ][env                      ] [Wallflower] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:26:00,403][INFO ][node                     ] [Wallflower] initialized
[2016-07-25 15:26:00,403][INFO ][node                     ] [Wallflower] starting ...
[2016-07-25 15:26:00,559][INFO ][transport                ] [Wallflower] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:26:00,567][WARN ][bootstrap                ] [Wallflower] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:26:04,613][INFO ][cluster.service          ] [Wallflower] new_master {Wallflower}{Ac83agjRTzO0UBS_hGpZKA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:26:04,681][INFO ][http                     ] [Wallflower] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:26:04,681][INFO ][node                     ] [Wallflower] started
[2016-07-25 15:26:04,879][WARN ][gateway                  ] [Wallflower] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:26:04,879][INFO ][gateway                  ] [Wallflower] recovered [1] indices into cluster_state
[2016-07-25 15:26:05,035][WARN ][gateway                  ] [Wallflower] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:26:05,328][WARN ][gateway                  ] [Wallflower] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:26:05,363][INFO ][cluster.routing.allocation] [Wallflower] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:26:05,366][WARN ][gateway                  ] [Wallflower] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:28:51,614][INFO ][node                     ] [Ghost] version[5.0.0-alpha3-SNAPSHOT], pid[768], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:28:51,614][INFO ][node                     ] [Ghost] initializing ...
[2016-07-25 15:28:51,621][INFO ][plugins                  ] [Ghost] modules [], plugins []
[2016-07-25 15:28:51,657][INFO ][env                      ] [Ghost] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:28:51,657][INFO ][env                      ] [Ghost] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:28:54,193][INFO ][node                     ] [Ghost] initialized
[2016-07-25 15:28:54,193][INFO ][node                     ] [Ghost] starting ...
[2016-07-25 15:28:54,354][INFO ][transport                ] [Ghost] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:28:54,358][WARN ][bootstrap                ] [Ghost] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:28:58,482][INFO ][cluster.service          ] [Ghost] new_master {Ghost}{3FaxgMB_TS-kqCoWEPpO9g}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:28:58,572][INFO ][http                     ] [Ghost] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:28:58,572][INFO ][node                     ] [Ghost] started
[2016-07-25 15:28:58,754][WARN ][gateway                  ] [Ghost] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:28:58,754][INFO ][gateway                  ] [Ghost] recovered [1] indices into cluster_state
[2016-07-25 15:28:58,909][WARN ][gateway                  ] [Ghost] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:28:59,200][WARN ][gateway                  ] [Ghost] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:28:59,240][INFO ][cluster.routing.allocation] [Ghost] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:28:59,243][WARN ][gateway                  ] [Ghost] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:30:51,462][INFO ][node                     ] [Diamond Lil] version[5.0.0-alpha3-SNAPSHOT], pid[2884], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:30:51,463][INFO ][node                     ] [Diamond Lil] initializing ...
[2016-07-25 15:30:51,468][INFO ][plugins                  ] [Diamond Lil] modules [], plugins []
[2016-07-25 15:30:51,501][INFO ][env                      ] [Diamond Lil] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:30:51,502][INFO ][env                      ] [Diamond Lil] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:30:54,033][INFO ][node                     ] [Diamond Lil] initialized
[2016-07-25 15:30:54,033][INFO ][node                     ] [Diamond Lil] starting ...
[2016-07-25 15:30:54,187][INFO ][transport                ] [Diamond Lil] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:30:54,194][WARN ][bootstrap                ] [Diamond Lil] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:30:58,291][INFO ][cluster.service          ] [Diamond Lil] new_master {Diamond Lil}{tm6eCUEIT9yhXuaV4jJKkQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:30:58,372][INFO ][http                     ] [Diamond Lil] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:30:58,372][INFO ][node                     ] [Diamond Lil] started
[2016-07-25 15:30:58,535][WARN ][gateway                  ] [Diamond Lil] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:30:58,535][INFO ][gateway                  ] [Diamond Lil] recovered [1] indices into cluster_state
[2016-07-25 15:30:58,673][WARN ][gateway                  ] [Diamond Lil] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:30:58,921][WARN ][gateway                  ] [Diamond Lil] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:30:58,960][INFO ][cluster.routing.allocation] [Diamond Lil] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][2]] ...]).
[2016-07-25 15:30:58,963][WARN ][gateway                  ] [Diamond Lil] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:32:24,520][INFO ][node                     ] [Jackson Arvad] version[5.0.0-alpha3-SNAPSHOT], pid[8544], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:32:24,521][INFO ][node                     ] [Jackson Arvad] initializing ...
[2016-07-25 15:32:24,529][INFO ][plugins                  ] [Jackson Arvad] modules [], plugins []
[2016-07-25 15:32:24,570][INFO ][env                      ] [Jackson Arvad] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:32:24,570][INFO ][env                      ] [Jackson Arvad] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:32:27,117][INFO ][node                     ] [Jackson Arvad] initialized
[2016-07-25 15:32:27,117][INFO ][node                     ] [Jackson Arvad] starting ...
[2016-07-25 15:32:27,304][INFO ][transport                ] [Jackson Arvad] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:32:27,309][WARN ][bootstrap                ] [Jackson Arvad] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:32:31,409][INFO ][cluster.service          ] [Jackson Arvad] new_master {Jackson Arvad}{rKAexYNvQrWBiDA-QK0TnA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:32:31,490][INFO ][http                     ] [Jackson Arvad] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:32:31,490][INFO ][node                     ] [Jackson Arvad] started
[2016-07-25 15:32:31,675][WARN ][gateway                  ] [Jackson Arvad] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:32:31,676][INFO ][gateway                  ] [Jackson Arvad] recovered [1] indices into cluster_state
[2016-07-25 15:32:31,840][WARN ][gateway                  ] [Jackson Arvad] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:32:32,110][WARN ][gateway                  ] [Jackson Arvad] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:32:32,176][INFO ][cluster.routing.allocation] [Jackson Arvad] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 15:32:32,178][WARN ][gateway                  ] [Jackson Arvad] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:33:59,555][INFO ][node                     ] [Baron Blood] version[5.0.0-alpha3-SNAPSHOT], pid[4924], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:33:59,556][INFO ][node                     ] [Baron Blood] initializing ...
[2016-07-25 15:33:59,564][INFO ][plugins                  ] [Baron Blood] modules [], plugins []
[2016-07-25 15:33:59,595][INFO ][env                      ] [Baron Blood] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:33:59,596][INFO ][env                      ] [Baron Blood] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:34:02,149][INFO ][node                     ] [Baron Blood] initialized
[2016-07-25 15:34:02,149][INFO ][node                     ] [Baron Blood] starting ...
[2016-07-25 15:34:02,321][INFO ][transport                ] [Baron Blood] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:34:02,328][WARN ][bootstrap                ] [Baron Blood] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:34:06,425][INFO ][cluster.service          ] [Baron Blood] new_master {Baron Blood}{nq9iRsbVQYeleQCL8uZ4eA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:34:06,502][INFO ][http                     ] [Baron Blood] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:34:06,502][INFO ][node                     ] [Baron Blood] started
[2016-07-25 15:34:06,687][WARN ][gateway                  ] [Baron Blood] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:34:06,688][INFO ][gateway                  ] [Baron Blood] recovered [1] indices into cluster_state
[2016-07-25 15:34:06,848][WARN ][gateway                  ] [Baron Blood] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:34:07,140][WARN ][gateway                  ] [Baron Blood] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:34:07,215][INFO ][cluster.routing.allocation] [Baron Blood] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 15:34:07,218][WARN ][gateway                  ] [Baron Blood] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:39:01,534][INFO ][node                     ] [Marrow] version[5.0.0-alpha3-SNAPSHOT], pid[9252], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:39:01,535][INFO ][node                     ] [Marrow] initializing ...
[2016-07-25 15:39:01,543][INFO ][plugins                  ] [Marrow] modules [], plugins []
[2016-07-25 15:39:01,580][INFO ][env                      ] [Marrow] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:39:01,580][INFO ][env                      ] [Marrow] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:39:04,116][INFO ][node                     ] [Marrow] initialized
[2016-07-25 15:39:04,117][INFO ][node                     ] [Marrow] starting ...
[2016-07-25 15:39:04,281][INFO ][transport                ] [Marrow] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:39:04,286][WARN ][bootstrap                ] [Marrow] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:39:08,377][INFO ][cluster.service          ] [Marrow] new_master {Marrow}{ivthqPiBSDmmwFNKtT8uVg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:39:08,471][INFO ][http                     ] [Marrow] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:39:08,471][INFO ][node                     ] [Marrow] started
[2016-07-25 15:39:08,644][WARN ][gateway                  ] [Marrow] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:39:08,644][INFO ][gateway                  ] [Marrow] recovered [1] indices into cluster_state
[2016-07-25 15:39:08,816][WARN ][gateway                  ] [Marrow] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:39:09,107][WARN ][gateway                  ] [Marrow] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:39:09,150][INFO ][cluster.routing.allocation] [Marrow] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:39:09,153][WARN ][gateway                  ] [Marrow] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:48:47,588][INFO ][node                     ] [Humus Sapien] version[5.0.0-alpha3-SNAPSHOT], pid[8688], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:48:47,588][INFO ][node                     ] [Humus Sapien] initializing ...
[2016-07-25 15:48:47,594][INFO ][plugins                  ] [Humus Sapien] modules [], plugins []
[2016-07-25 15:48:47,627][INFO ][env                      ] [Humus Sapien] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:48:47,627][INFO ][env                      ] [Humus Sapien] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:48:50,467][INFO ][node                     ] [Humus Sapien] initialized
[2016-07-25 15:48:50,467][INFO ][node                     ] [Humus Sapien] starting ...
[2016-07-25 15:48:50,649][INFO ][transport                ] [Humus Sapien] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:48:50,658][WARN ][bootstrap                ] [Humus Sapien] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:48:54,754][INFO ][cluster.service          ] [Humus Sapien] new_master {Humus Sapien}{bdWs9h8MRqCkSnUnLjQ2CQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:48:54,841][INFO ][http                     ] [Humus Sapien] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:48:54,841][INFO ][node                     ] [Humus Sapien] started
[2016-07-25 15:48:55,044][WARN ][gateway                  ] [Humus Sapien] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:48:55,044][INFO ][gateway                  ] [Humus Sapien] recovered [1] indices into cluster_state
[2016-07-25 15:48:55,214][WARN ][gateway                  ] [Humus Sapien] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:48:55,482][WARN ][gateway                  ] [Humus Sapien] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:48:55,518][INFO ][cluster.routing.allocation] [Humus Sapien] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][2]] ...]).
[2016-07-25 15:48:55,521][WARN ][gateway                  ] [Humus Sapien] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:49:34,570][INFO ][node                     ] [Ox] version[5.0.0-alpha3-SNAPSHOT], pid[6524], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:49:34,570][INFO ][node                     ] [Ox] initializing ...
[2016-07-25 15:49:34,576][INFO ][plugins                  ] [Ox] modules [], plugins []
[2016-07-25 15:49:34,610][INFO ][env                      ] [Ox] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:49:34,610][INFO ][env                      ] [Ox] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:49:37,114][INFO ][node                     ] [Ox] initialized
[2016-07-25 15:49:37,114][INFO ][node                     ] [Ox] starting ...
[2016-07-25 15:49:37,272][INFO ][transport                ] [Ox] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:49:37,279][WARN ][bootstrap                ] [Ox] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:49:41,330][INFO ][cluster.service          ] [Ox] new_master {Ox}{9Xv9xKZ0R4iwGiwZTb4DIw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:49:41,392][INFO ][http                     ] [Ox] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:49:41,392][INFO ][node                     ] [Ox] started
[2016-07-25 15:49:41,582][WARN ][gateway                  ] [Ox] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:49:41,582][INFO ][gateway                  ] [Ox] recovered [1] indices into cluster_state
[2016-07-25 15:49:41,741][WARN ][gateway                  ] [Ox] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:49:42,010][WARN ][gateway                  ] [Ox] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:49:42,059][INFO ][cluster.routing.allocation] [Ox] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 15:49:42,062][WARN ][gateway                  ] [Ox] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:50:20,909][INFO ][node                     ] [Inferno] version[5.0.0-alpha3-SNAPSHOT], pid[556], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:50:20,910][INFO ][node                     ] [Inferno] initializing ...
[2016-07-25 15:50:20,917][INFO ][plugins                  ] [Inferno] modules [], plugins []
[2016-07-25 15:50:20,949][INFO ][env                      ] [Inferno] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:50:20,950][INFO ][env                      ] [Inferno] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:50:23,346][INFO ][node                     ] [Inferno] initialized
[2016-07-25 15:50:23,346][INFO ][node                     ] [Inferno] starting ...
[2016-07-25 15:50:23,512][INFO ][transport                ] [Inferno] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:50:23,520][WARN ][bootstrap                ] [Inferno] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:50:27,575][INFO ][cluster.service          ] [Inferno] new_master {Inferno}{jiE9aL51Qh2uBMK5QlCr1w}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:50:27,644][INFO ][http                     ] [Inferno] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:50:27,644][INFO ][node                     ] [Inferno] started
[2016-07-25 15:50:27,869][WARN ][gateway                  ] [Inferno] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:50:27,869][INFO ][gateway                  ] [Inferno] recovered [1] indices into cluster_state
[2016-07-25 15:50:28,012][WARN ][gateway                  ] [Inferno] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:50:28,272][WARN ][gateway                  ] [Inferno] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:50:28,303][INFO ][cluster.routing.allocation] [Inferno] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][2]] ...]).
[2016-07-25 15:50:28,306][WARN ][gateway                  ] [Inferno] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:11,062][INFO ][node                     ] [Arkady Rossovich] version[5.0.0-alpha3-SNAPSHOT], pid[7032], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:58:11,062][INFO ][node                     ] [Arkady Rossovich] initializing ...
[2016-07-25 15:58:11,070][INFO ][plugins                  ] [Arkady Rossovich] modules [], plugins []
[2016-07-25 15:58:11,113][INFO ][env                      ] [Arkady Rossovich] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:58:11,114][INFO ][env                      ] [Arkady Rossovich] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:58:13,756][INFO ][node                     ] [Arkady Rossovich] initialized
[2016-07-25 15:58:13,756][INFO ][node                     ] [Arkady Rossovich] starting ...
[2016-07-25 15:58:13,931][INFO ][transport                ] [Arkady Rossovich] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:58:13,939][WARN ][bootstrap                ] [Arkady Rossovich] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:58:17,990][INFO ][cluster.service          ] [Arkady Rossovich] new_master {Arkady Rossovich}{7n5MaAoQTT6zupRO2gFLQA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:58:18,053][INFO ][http                     ] [Arkady Rossovich] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:58:18,053][INFO ][node                     ] [Arkady Rossovich] started
[2016-07-25 15:58:18,278][WARN ][gateway                  ] [Arkady Rossovich] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:18,278][INFO ][gateway                  ] [Arkady Rossovich] recovered [1] indices into cluster_state
[2016-07-25 15:58:18,425][WARN ][gateway                  ] [Arkady Rossovich] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:18,695][WARN ][gateway                  ] [Arkady Rossovich] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:18,732][INFO ][cluster.routing.allocation] [Arkady Rossovich] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 15:58:18,735][WARN ][gateway                  ] [Arkady Rossovich] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:47,966][INFO ][node                     ] [Atom Bob] version[5.0.0-alpha3-SNAPSHOT], pid[6164], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:58:47,966][INFO ][node                     ] [Atom Bob] initializing ...
[2016-07-25 15:58:47,971][INFO ][plugins                  ] [Atom Bob] modules [], plugins []
[2016-07-25 15:58:48,000][INFO ][env                      ] [Atom Bob] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:58:48,000][INFO ][env                      ] [Atom Bob] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:58:50,570][INFO ][node                     ] [Atom Bob] initialized
[2016-07-25 15:58:50,570][INFO ][node                     ] [Atom Bob] starting ...
[2016-07-25 15:58:50,733][INFO ][transport                ] [Atom Bob] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:58:50,738][WARN ][bootstrap                ] [Atom Bob] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:58:54,804][INFO ][cluster.service          ] [Atom Bob] new_master {Atom Bob}{6QYGnUitSgy5PjlnXrcUpQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:58:54,865][INFO ][http                     ] [Atom Bob] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:58:54,865][INFO ][node                     ] [Atom Bob] started
[2016-07-25 15:58:55,053][WARN ][gateway                  ] [Atom Bob] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:55,053][INFO ][gateway                  ] [Atom Bob] recovered [1] indices into cluster_state
[2016-07-25 15:58:55,202][WARN ][gateway                  ] [Atom Bob] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:55,487][WARN ][gateway                  ] [Atom Bob] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:58:55,516][INFO ][cluster.routing.allocation] [Atom Bob] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 15:58:55,518][WARN ][gateway                  ] [Atom Bob] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:12,998][INFO ][node                     ] [Kasper Cole] version[5.0.0-alpha3-SNAPSHOT], pid[8104], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:59:12,998][INFO ][node                     ] [Kasper Cole] initializing ...
[2016-07-25 15:59:13,004][INFO ][plugins                  ] [Kasper Cole] modules [], plugins []
[2016-07-25 15:59:13,036][INFO ][env                      ] [Kasper Cole] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:59:13,036][INFO ][env                      ] [Kasper Cole] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:59:15,630][INFO ][node                     ] [Kasper Cole] initialized
[2016-07-25 15:59:15,631][INFO ][node                     ] [Kasper Cole] starting ...
[2016-07-25 15:59:15,799][INFO ][transport                ] [Kasper Cole] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:59:15,803][WARN ][bootstrap                ] [Kasper Cole] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:59:19,899][INFO ][cluster.service          ] [Kasper Cole] new_master {Kasper Cole}{7tSFgNtHT9SPUWdPEsL_Ng}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:59:19,978][INFO ][http                     ] [Kasper Cole] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:59:19,978][INFO ][node                     ] [Kasper Cole] started
[2016-07-25 15:59:20,138][WARN ][gateway                  ] [Kasper Cole] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:20,138][INFO ][gateway                  ] [Kasper Cole] recovered [1] indices into cluster_state
[2016-07-25 15:59:20,230][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,232][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,244][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,244][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,250][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,251][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,255][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][1]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,256][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][1]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,261][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,261][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,269][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,269][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: ShardNotFoundException[no such shard];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] ShardNotFoundException[no such shard]
	at org.elasticsearch.index.IndexService.getShard(IndexService.java:197)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:544)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,274][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,274][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,280][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,280][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,286][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,286][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,292][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,292][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,297][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,298][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,304][WARN ][gateway                  ] [Kasper Cole] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:20,305][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,305][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,310][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,311][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,319][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,319][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,322][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,322][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,329][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,329][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,335][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,335][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,342][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,342][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,349][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,349][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,353][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,355][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,360][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,360][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,367][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,368][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,373][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,374][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,386][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,387][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,393][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,394][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,398][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,399][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,404][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,405][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,411][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,412][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,417][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,417][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,422][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,422][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,428][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,429][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,434][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,434][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,441][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,441][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,448][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,448][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,458][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,458][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,468][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,468][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,473][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,473][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,479][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,480][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,486][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,486][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,491][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,493][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,497][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,497][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,504][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,506][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,515][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,516][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,521][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,522][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,527][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,528][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,534][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,536][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][2]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,539][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,539][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,546][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,547][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][3]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,550][DEBUG][action.search            ] [Kasper Cole] All shards failed for phase: [query]
RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,550][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [query], all shards failed
	at org.elasticsearch.action.search.AbstractSearchAsyncAction.onFirstPhaseResult(AbstractSearchAsyncAction.java:225)
	at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:167)
	at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)
	at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:939)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.processException(TransportService.java:1040)
	at org.elasticsearch.transport.TransportService$DirectResponseChannel.sendResponse(TransportService.java:1018)
	at org.elasticsearch.transport.TransportService$5.onFailure(TransportService.java:533)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: RemoteTransportException[[Kasper Cole][127.0.0.1:9300][indices:data/read/search[phase/query]]]; nested: IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]];
Caused by: [products/iReCozPrS7eiG68iv1DyNg][[products][4]] IllegalIndexShardStateException[CurrentState[RECOVERING] operations only allowed when shard state is one of [POST_RECOVERY, STARTED, RELOCATED]]
	at org.elasticsearch.index.shard.IndexShard.readAllowed(IndexShard.java:1002)
	at org.elasticsearch.index.shard.IndexShard.acquireSearcher(IndexShard.java:800)
	at org.elasticsearch.search.SearchService.createContext(SearchService.java:547)
	at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:525)
	at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:276)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:315)
	at org.elasticsearch.search.action.SearchTransportService$SearchQueryTransportHandler.messageReceived(SearchTransportService.java:312)
	at org.elasticsearch.transport.TransportRequestHandler.messageReceived(TransportRequestHandler.java:33)
	at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)
	at org.elasticsearch.transport.TransportService$5.doRun(TransportService.java:522)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2016-07-25 15:59:20,646][WARN ][gateway                  ] [Kasper Cole] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:20,651][WARN ][gateway                  ] [Kasper Cole] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:20,729][INFO ][cluster.routing.allocation] [Kasper Cole] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 15:59:20,732][WARN ][gateway                  ] [Kasper Cole] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:29,197][INFO ][node                     ] [Slither] version[5.0.0-alpha3-SNAPSHOT], pid[1668], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 15:59:29,198][INFO ][node                     ] [Slither] initializing ...
[2016-07-25 15:59:29,204][INFO ][plugins                  ] [Slither] modules [], plugins []
[2016-07-25 15:59:29,236][INFO ][env                      ] [Slither] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 15:59:29,236][INFO ][env                      ] [Slither] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 15:59:31,779][INFO ][node                     ] [Slither] initialized
[2016-07-25 15:59:31,779][INFO ][node                     ] [Slither] starting ...
[2016-07-25 15:59:31,946][INFO ][transport                ] [Slither] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 15:59:31,951][WARN ][bootstrap                ] [Slither] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 15:59:36,041][INFO ][cluster.service          ] [Slither] new_master {Slither}{5ut4pO_sTH2wshsjeqvTHA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 15:59:36,125][INFO ][http                     ] [Slither] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 15:59:36,125][INFO ][node                     ] [Slither] started
[2016-07-25 15:59:36,307][WARN ][gateway                  ] [Slither] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:36,307][INFO ][gateway                  ] [Slither] recovered [1] indices into cluster_state
[2016-07-25 15:59:36,455][WARN ][gateway                  ] [Slither] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:36,717][WARN ][gateway                  ] [Slither] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 15:59:36,751][INFO ][cluster.routing.allocation] [Slither] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][2]] ...]).
[2016-07-25 15:59:36,753][WARN ][gateway                  ] [Slither] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:01:32,660][INFO ][node                     ] [Left Hand] version[5.0.0-alpha3-SNAPSHOT], pid[5932], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:01:32,660][INFO ][node                     ] [Left Hand] initializing ...
[2016-07-25 16:01:32,680][INFO ][plugins                  ] [Left Hand] modules [], plugins []
[2016-07-25 16:01:32,729][INFO ][env                      ] [Left Hand] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:01:32,729][INFO ][env                      ] [Left Hand] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:01:42,559][INFO ][node                     ] [Left Hand] initialized
[2016-07-25 16:01:42,559][INFO ][node                     ] [Left Hand] starting ...
[2016-07-25 16:01:42,765][INFO ][transport                ] [Left Hand] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:01:42,795][WARN ][bootstrap                ] [Left Hand] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:01:47,054][INFO ][cluster.service          ] [Left Hand] new_master {Left Hand}{kR8nO2m8QPan7F-rl6kjDQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:01:47,138][INFO ][http                     ] [Left Hand] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:01:47,139][INFO ][node                     ] [Left Hand] started
[2016-07-25 16:01:47,841][WARN ][gateway                  ] [Left Hand] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:01:47,841][INFO ][gateway                  ] [Left Hand] recovered [1] indices into cluster_state
[2016-07-25 16:01:48,139][WARN ][gateway                  ] [Left Hand] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:01:48,577][WARN ][gateway                  ] [Left Hand] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:01:48,643][INFO ][cluster.routing.allocation] [Left Hand] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 16:01:48,645][WARN ][gateway                  ] [Left Hand] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:04:13,705][INFO ][node                     ] [Deathlok] version[5.0.0-alpha3-SNAPSHOT], pid[3992], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:04:13,706][INFO ][node                     ] [Deathlok] initializing ...
[2016-07-25 16:04:13,714][INFO ][plugins                  ] [Deathlok] modules [], plugins []
[2016-07-25 16:04:13,747][INFO ][env                      ] [Deathlok] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:04:13,747][INFO ][env                      ] [Deathlok] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:04:16,478][INFO ][node                     ] [Deathlok] initialized
[2016-07-25 16:04:16,478][INFO ][node                     ] [Deathlok] starting ...
[2016-07-25 16:04:16,642][INFO ][transport                ] [Deathlok] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:04:16,647][WARN ][bootstrap                ] [Deathlok] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:04:20,731][INFO ][cluster.service          ] [Deathlok] new_master {Deathlok}{2ZnK-wjoT2ahW5Y-Xq8ahw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:04:20,801][INFO ][http                     ] [Deathlok] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:04:20,801][INFO ][node                     ] [Deathlok] started
[2016-07-25 16:04:20,985][WARN ][gateway                  ] [Deathlok] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:04:20,985][INFO ][gateway                  ] [Deathlok] recovered [1] indices into cluster_state
[2016-07-25 16:04:21,130][WARN ][gateway                  ] [Deathlok] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:04:21,398][WARN ][gateway                  ] [Deathlok] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:04:21,455][INFO ][cluster.routing.allocation] [Deathlok] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 16:04:21,457][WARN ][gateway                  ] [Deathlok] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:06:42,519][INFO ][node                     ] [Mother Earth] version[5.0.0-alpha3-SNAPSHOT], pid[7052], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:06:42,520][INFO ][node                     ] [Mother Earth] initializing ...
[2016-07-25 16:06:42,527][INFO ][plugins                  ] [Mother Earth] modules [], plugins []
[2016-07-25 16:06:42,561][INFO ][env                      ] [Mother Earth] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:06:42,562][INFO ][env                      ] [Mother Earth] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:06:45,013][INFO ][node                     ] [Mother Earth] initialized
[2016-07-25 16:06:45,013][INFO ][node                     ] [Mother Earth] starting ...
[2016-07-25 16:06:45,191][INFO ][transport                ] [Mother Earth] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:06:45,199][WARN ][bootstrap                ] [Mother Earth] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:06:49,247][INFO ][cluster.service          ] [Mother Earth] new_master {Mother Earth}{LWFJ8V0XTJS2ZeOCQav9RQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:06:49,312][INFO ][http                     ] [Mother Earth] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:06:49,312][INFO ][node                     ] [Mother Earth] started
[2016-07-25 16:06:49,494][WARN ][gateway                  ] [Mother Earth] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:06:49,495][INFO ][gateway                  ] [Mother Earth] recovered [1] indices into cluster_state
[2016-07-25 16:06:49,652][WARN ][gateway                  ] [Mother Earth] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:06:49,936][WARN ][gateway                  ] [Mother Earth] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:06:49,984][INFO ][cluster.routing.allocation] [Mother Earth] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 16:06:49,987][WARN ][gateway                  ] [Mother Earth] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:09:25,491][INFO ][node                     ] [Deathstroke] version[5.0.0-alpha3-SNAPSHOT], pid[6748], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:09:25,492][INFO ][node                     ] [Deathstroke] initializing ...
[2016-07-25 16:09:25,500][INFO ][plugins                  ] [Deathstroke] modules [], plugins []
[2016-07-25 16:09:25,538][INFO ][env                      ] [Deathstroke] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:09:25,538][INFO ][env                      ] [Deathstroke] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:09:28,054][INFO ][node                     ] [Deathstroke] initialized
[2016-07-25 16:09:28,054][INFO ][node                     ] [Deathstroke] starting ...
[2016-07-25 16:09:28,218][INFO ][transport                ] [Deathstroke] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:09:28,222][WARN ][bootstrap                ] [Deathstroke] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:09:32,304][INFO ][cluster.service          ] [Deathstroke] new_master {Deathstroke}{DgB-ZNolRtelJdpbF8RtDg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:09:32,376][INFO ][http                     ] [Deathstroke] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:09:32,377][INFO ][node                     ] [Deathstroke] started
[2016-07-25 16:09:32,564][WARN ][gateway                  ] [Deathstroke] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:09:32,565][INFO ][gateway                  ] [Deathstroke] recovered [1] indices into cluster_state
[2016-07-25 16:09:32,701][WARN ][gateway                  ] [Deathstroke] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:09:32,984][WARN ][gateway                  ] [Deathstroke] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:09:33,018][INFO ][cluster.routing.allocation] [Deathstroke] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][1]] ...]).
[2016-07-25 16:09:33,021][WARN ][gateway                  ] [Deathstroke] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:40:43,523][INFO ][node                     ] [Colleen Wing] version[5.0.0-alpha3-SNAPSHOT], pid[9236], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:40:43,524][INFO ][node                     ] [Colleen Wing] initializing ...
[2016-07-25 16:40:43,531][INFO ][plugins                  ] [Colleen Wing] modules [], plugins []
[2016-07-25 16:40:43,568][INFO ][env                      ] [Colleen Wing] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:40:43,569][INFO ][env                      ] [Colleen Wing] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:40:46,147][INFO ][node                     ] [Colleen Wing] initialized
[2016-07-25 16:40:46,147][INFO ][node                     ] [Colleen Wing] starting ...
[2016-07-25 16:40:46,338][INFO ][transport                ] [Colleen Wing] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:40:46,346][WARN ][bootstrap                ] [Colleen Wing] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:40:50,410][INFO ][cluster.service          ] [Colleen Wing] new_master {Colleen Wing}{C52cHcuQRbm2hhzMSo4Yjw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:40:50,478][INFO ][http                     ] [Colleen Wing] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:40:50,479][INFO ][node                     ] [Colleen Wing] started
[2016-07-25 16:40:50,671][WARN ][gateway                  ] [Colleen Wing] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:40:50,672][INFO ][gateway                  ] [Colleen Wing] recovered [1] indices into cluster_state
[2016-07-25 16:40:50,826][WARN ][gateway                  ] [Colleen Wing] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:40:51,116][WARN ][gateway                  ] [Colleen Wing] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:40:51,144][INFO ][cluster.routing.allocation] [Colleen Wing] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][2]] ...]).
[2016-07-25 16:40:51,147][WARN ][gateway                  ] [Colleen Wing] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:42:22,036][INFO ][node                     ] [Necrodamus] version[5.0.0-alpha3-SNAPSHOT], pid[7296], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:42:22,037][INFO ][node                     ] [Necrodamus] initializing ...
[2016-07-25 16:42:22,045][INFO ][plugins                  ] [Necrodamus] modules [], plugins []
[2016-07-25 16:42:22,080][INFO ][env                      ] [Necrodamus] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:42:22,080][INFO ][env                      ] [Necrodamus] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:42:24,569][INFO ][node                     ] [Necrodamus] initialized
[2016-07-25 16:42:24,569][INFO ][node                     ] [Necrodamus] starting ...
[2016-07-25 16:42:24,746][INFO ][transport                ] [Necrodamus] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:42:24,754][WARN ][bootstrap                ] [Necrodamus] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:42:28,839][INFO ][cluster.service          ] [Necrodamus] new_master {Necrodamus}{4M4nQj09T4Od3UFf6lZLow}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:42:28,919][INFO ][http                     ] [Necrodamus] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:42:28,919][INFO ][node                     ] [Necrodamus] started
[2016-07-25 16:42:29,102][WARN ][gateway                  ] [Necrodamus] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:42:29,102][INFO ][gateway                  ] [Necrodamus] recovered [1] indices into cluster_state
[2016-07-25 16:42:29,273][WARN ][gateway                  ] [Necrodamus] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:42:29,547][WARN ][gateway                  ] [Necrodamus] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:42:29,611][INFO ][cluster.routing.allocation] [Necrodamus] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][0]] ...]).
[2016-07-25 16:42:29,614][WARN ][gateway                  ] [Necrodamus] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:44:23,113][INFO ][node                     ] [Alicia Masters] version[5.0.0-alpha3-SNAPSHOT], pid[1692], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:44:23,114][INFO ][node                     ] [Alicia Masters] initializing ...
[2016-07-25 16:44:23,121][INFO ][plugins                  ] [Alicia Masters] modules [], plugins []
[2016-07-25 16:44:23,155][INFO ][env                      ] [Alicia Masters] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:44:23,156][INFO ][env                      ] [Alicia Masters] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:44:25,666][INFO ][node                     ] [Alicia Masters] initialized
[2016-07-25 16:44:25,666][INFO ][node                     ] [Alicia Masters] starting ...
[2016-07-25 16:44:25,832][INFO ][transport                ] [Alicia Masters] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:44:25,836][WARN ][bootstrap                ] [Alicia Masters] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:44:29,878][INFO ][cluster.service          ] [Alicia Masters] new_master {Alicia Masters}{sVo_hcAXSl2L77Z3n2DCrQ}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:44:29,939][INFO ][http                     ] [Alicia Masters] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:44:29,939][INFO ][node                     ] [Alicia Masters] started
[2016-07-25 16:44:30,124][WARN ][gateway                  ] [Alicia Masters] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:44:30,125][INFO ][gateway                  ] [Alicia Masters] recovered [1] indices into cluster_state
[2016-07-25 16:44:30,270][WARN ][gateway                  ] [Alicia Masters] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:44:30,554][WARN ][gateway                  ] [Alicia Masters] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:44:30,586][INFO ][cluster.routing.allocation] [Alicia Masters] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][4]] ...]).
[2016-07-25 16:44:30,588][WARN ][gateway                  ] [Alicia Masters] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:49:27,664][INFO ][node                     ] [Anaconda] version[5.0.0-alpha3-SNAPSHOT], pid[6284], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:49:27,664][INFO ][node                     ] [Anaconda] initializing ...
[2016-07-25 16:49:27,671][INFO ][plugins                  ] [Anaconda] modules [], plugins []
[2016-07-25 16:49:27,706][INFO ][env                      ] [Anaconda] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:49:27,706][INFO ][env                      ] [Anaconda] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:49:30,364][INFO ][node                     ] [Anaconda] initialized
[2016-07-25 16:49:30,364][INFO ][node                     ] [Anaconda] starting ...
[2016-07-25 16:49:47,657][INFO ][node                     ] [Gauntlet] version[5.0.0-alpha3-SNAPSHOT], pid[7180], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:49:47,658][INFO ][node                     ] [Gauntlet] initializing ...
[2016-07-25 16:49:47,665][INFO ][plugins                  ] [Gauntlet] modules [], plugins []
[2016-07-25 16:49:47,703][INFO ][env                      ] [Gauntlet] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:49:47,703][INFO ][env                      ] [Gauntlet] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:49:50,387][INFO ][node                     ] [Gauntlet] initialized
[2016-07-25 16:49:50,387][INFO ][node                     ] [Gauntlet] starting ...
[2016-07-25 16:49:50,554][INFO ][transport                ] [Gauntlet] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:49:50,558][WARN ][bootstrap                ] [Gauntlet] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:49:54,627][INFO ][cluster.service          ] [Gauntlet] new_master {Gauntlet}{iV4Ve0zqQl2Yp1-W3Lvsxg}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:49:54,710][INFO ][http                     ] [Gauntlet] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:49:54,710][INFO ][node                     ] [Gauntlet] started
[2016-07-25 16:49:54,965][WARN ][gateway                  ] [Gauntlet] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:49:54,965][INFO ][gateway                  ] [Gauntlet] recovered [1] indices into cluster_state
[2016-07-25 16:49:55,166][WARN ][gateway                  ] [Gauntlet] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:49:55,499][WARN ][gateway                  ] [Gauntlet] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:49:55,565][INFO ][cluster.routing.allocation] [Gauntlet] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 16:49:55,569][WARN ][gateway                  ] [Gauntlet] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:50:02,519][DEBUG][action.search            ] [Gauntlet] failed to reduce search
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: Exception while calling URL:http://odoscope.cloud/praxisdienst.de/decisions?maxItems=20&token=XfRqxAgR7XwGW3qzmj2Mxw&categoryID=2dd41e75a881635aa52be72e7f6d2eeb&prodId=421109&hostname=praxisdienst.de
	at org.elasticsearch.search.controller.SearchPhaseController.callURL(SearchPhaseController.java:746)
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:490)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
Caused by: java.security.AccessControlException: access denied ("java.util.PropertyPermission" "http.agent" "write")
	at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)
	at java.security.AccessController.checkPermission(AccessController.java:884)
	at java.lang.SecurityManager.checkPermission(SecurityManager.java:549)
	at java.lang.System.setProperty(System.java:792)
	at org.elasticsearch.search.controller.SearchPhaseController.callURL(SearchPhaseController.java:722)
	... 7 more
[2016-07-25 16:50:02,523][WARN ][rest.suppressed          ] path: /products/_search, params: {index=products}
Failed to execute phase [fetch], [reduce] 
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.onFailure(SearchQueryThenFetchAsyncAction.java:156)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.onFailure(ThreadContext.java:438)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:39)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: Exception while calling URL:http://odoscope.cloud/praxisdienst.de/decisions?maxItems=20&token=XfRqxAgR7XwGW3qzmj2Mxw&categoryID=2dd41e75a881635aa52be72e7f6d2eeb&prodId=421109&hostname=praxisdienst.de
	at org.elasticsearch.search.controller.SearchPhaseController.callURL(SearchPhaseController.java:746)
	at org.elasticsearch.search.controller.SearchPhaseController.merge(SearchPhaseController.java:490)
	at org.elasticsearch.action.search.SearchQueryThenFetchAsyncAction$2.doRun(SearchQueryThenFetchAsyncAction.java:132)
	at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:452)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)
	... 3 more
Caused by: java.security.AccessControlException: access denied ("java.util.PropertyPermission" "http.agent" "write")
	at java.security.AccessControlContext.checkPermission(AccessControlContext.java:472)
	at java.security.AccessController.checkPermission(AccessController.java:884)
	at java.lang.SecurityManager.checkPermission(SecurityManager.java:549)
	at java.lang.System.setProperty(System.java:792)
	at org.elasticsearch.search.controller.SearchPhaseController.callURL(SearchPhaseController.java:722)
	... 7 more
[2016-07-25 16:56:02,528][INFO ][node                     ] [Zabu] version[5.0.0-alpha3-SNAPSHOT], pid[9196], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 16:56:02,528][INFO ][node                     ] [Zabu] initializing ...
[2016-07-25 16:56:02,535][INFO ][plugins                  ] [Zabu] modules [], plugins []
[2016-07-25 16:56:02,566][INFO ][env                      ] [Zabu] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 16:56:02,566][INFO ][env                      ] [Zabu] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 16:56:05,227][INFO ][node                     ] [Zabu] initialized
[2016-07-25 16:56:05,227][INFO ][node                     ] [Zabu] starting ...
[2016-07-25 16:56:05,406][INFO ][transport                ] [Zabu] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 16:56:05,411][WARN ][bootstrap                ] [Zabu] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 16:56:09,499][INFO ][cluster.service          ] [Zabu] new_master {Zabu}{S_HC4PlVTuKaB8pFXFHdaw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 16:56:09,580][INFO ][http                     ] [Zabu] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 16:56:09,580][INFO ][node                     ] [Zabu] started
[2016-07-25 16:56:09,764][WARN ][gateway                  ] [Zabu] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:56:09,764][INFO ][gateway                  ] [Zabu] recovered [1] indices into cluster_state
[2016-07-25 16:56:09,909][WARN ][gateway                  ] [Zabu] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:56:10,177][WARN ][gateway                  ] [Zabu] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 16:56:10,204][INFO ][cluster.routing.allocation] [Zabu] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 16:56:10,216][WARN ][gateway                  ] [Zabu] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 17:01:39,989][INFO ][node                     ] [Demiurge] version[5.0.0-alpha3-SNAPSHOT], pid[8928], build[Unknown/Unknown], OS[Windows 10/10.0/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_91/25.91-b15]
[2016-07-25 17:01:39,990][INFO ][node                     ] [Demiurge] initializing ...
[2016-07-25 17:01:39,995][INFO ][plugins                  ] [Demiurge] modules [], plugins []
[2016-07-25 17:01:40,023][INFO ][env                      ] [Demiurge] using [1] data paths, mounts [[OS (C:)]], net usable_space [78.4gb], net total_space [226.2gb], spins? [unknown], types [NTFS]
[2016-07-25 17:01:40,024][INFO ][env                      ] [Demiurge] heap size [3.9gb], compressed ordinary object pointers [true]
[2016-07-25 17:01:42,567][INFO ][node                     ] [Demiurge] initialized
[2016-07-25 17:01:42,567][INFO ][node                     ] [Demiurge] starting ...
[2016-07-25 17:01:42,727][INFO ][transport                ] [Demiurge] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-07-25 17:01:42,735][WARN ][bootstrap                ] [Demiurge] please set [discovery.zen.minimum_master_nodes] to a majority of the number of master eligible nodes in your cluster
[2016-07-25 17:01:46,834][INFO ][cluster.service          ] [Demiurge] new_master {Demiurge}{gKofhaeWRde9hu-0lIHVmw}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-07-25 17:01:46,905][INFO ][http                     ] [Demiurge] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-07-25 17:01:46,906][INFO ][node                     ] [Demiurge] started
[2016-07-25 17:01:47,067][WARN ][gateway                  ] [Demiurge] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 17:01:47,068][INFO ][gateway                  ] [Demiurge] recovered [1] indices into cluster_state
[2016-07-25 17:01:47,207][WARN ][gateway                  ] [Demiurge] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 17:01:47,437][WARN ][gateway                  ] [Demiurge] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
[2016-07-25 17:01:47,469][INFO ][cluster.routing.allocation] [Demiurge] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[products][3]] ...]).
[2016-07-25 17:01:47,472][WARN ][gateway                  ] [Demiurge] [[products/xQepTdIXT8OjWCXFOQPOmw]] can not be imported as a dangling index, as index with same name already exists in cluster metadata
